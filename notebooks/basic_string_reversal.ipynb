{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "## Building a GPT\n",
    "\n",
    "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [] \n",
    "with open(\"output_data_50.txt\",\"r\") as f:\n",
    "    sentences = f.readlines()\n",
    "sentences[:10]\n",
    "\n",
    "text = \"\".join(sentences[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# at beginning of the script\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e-Rbyr8sfM8",
    "outputId": "f34e94a9-5b44-4cf3-885b-986731929109",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?^_abcdefghijklmnopqrstuvwxyz\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paulina:true, too true, my lord:if, one by one_eno yb eno ,fi:drol ym ,eurt oot ,eurt:aniluap^\\nr he '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw1LKNCgwjj1",
    "outputId": "86fcc21c-2cf7-40d9-cd7b-b5a253da4459",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 23, 23, 1, 34, 22, 19, 32, 19]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJb0OXPwzvqg",
    "outputId": "db7297cc-36a9-4fae-e941-e7bb9e0e91d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([993982]) torch.int64\n",
      "tensor([30, 15, 35, 26, 23, 28, 15, 10, 34, 32, 35, 19,  6,  1, 34, 29, 29,  1,\n",
      "        34, 32, 35, 19,  6,  1, 27, 39,  1, 26, 29, 32, 18, 10, 23, 20,  6,  1,\n",
      "        29, 28, 19,  1, 16, 39,  1, 29, 28, 19, 14, 19, 28, 29,  1, 39, 16,  1,\n",
      "        19, 28, 29,  1,  6, 20, 23, 10, 18, 32, 29, 26,  1, 39, 27,  1,  6, 19,\n",
      "        35, 32, 34,  1, 29, 29, 34,  1,  6, 19, 35, 32, 34, 10, 15, 28, 23, 26,\n",
      "        35, 15, 30, 13,  0, 32,  1, 22, 19,  1, 27, 15, 25, 19,  1, 22, 23, 33,\n",
      "         1, 37, 15, 39, 35, 28, 18, 19, 32,  1, 34, 22, 19,  1, 17, 29, 26, 29,\n",
      "        35, 32,  1, 29, 20,  1, 22, 23, 33,  1, 35, 33, 35, 15, 26,  1, 21, 15,\n",
      "        14, 15, 21,  1, 26, 15, 35, 33, 35,  1, 33, 23, 22,  1, 20, 29,  1, 32,\n",
      "        35, 29, 26, 29, 17,  1, 19, 22, 34,  1, 32, 19, 18, 28, 35, 39, 15, 37,\n",
      "         1, 33, 23, 22,  1, 19, 25, 15, 27,  1, 19, 22,  1, 32, 13,  0, 33, 15,\n",
      "        21, 19, 33,  6,  1, 15, 28, 18,  1, 23, 28,  1, 34, 22, 19,  1, 19, 28,\n",
      "        18,  6, 22, 15, 36, 23, 28, 21,  1, 27, 39,  1, 20, 32, 19, 19, 18, 29,\n",
      "        27,  6,  1, 16, 29, 15, 33, 34,  1, 29, 20, 14, 20, 29,  1, 34, 33, 15,\n",
      "        29, 16,  1,  6, 27, 29, 18, 19, 19, 32, 20,  1, 39, 27,  1, 21, 28, 23,\n",
      "        36, 15, 22,  6, 18, 28, 19,  1, 19, 22, 34,  1, 28, 23,  1, 18, 28, 15,\n",
      "         1,  6, 33, 19, 21, 15, 33, 13,  0, 28, 21,  1, 22, 19, 28, 32, 39,  1,\n",
      "        36, 23, 32, 23, 17, 22, 15, 32, 18, 10, 28, 29, 37,  6,  1, 17, 26, 23,\n",
      "        20, 20, 29, 32, 18,  6,  1, 23,  1, 22, 15, 36, 19,  1, 33, 23, 28, 21,\n",
      "        26, 19, 14, 19, 26, 21, 28, 23, 33,  1, 19, 36, 15, 22,  1, 23,  1,  6,\n",
      "        18, 32, 29, 20, 20, 23, 26, 17,  1,  6, 37, 29, 28, 10, 18, 32, 15, 22,\n",
      "        17, 23, 32, 23, 36,  1, 39, 32, 28, 19, 22,  1, 21, 28, 13,  0,  7, 18,\n",
      "        15, 27, 28,  1, 22, 23, 27,  8,  1, 16, 19,  1, 33, 22, 19,  1, 22, 29,\n",
      "        28, 29, 35, 32,  7, 20, 26, 15, 37,  5, 18,  6, 23,  1, 22, 15, 36, 19,\n",
      "         1, 34, 22, 32, 19, 19,  1, 18, 15, 35, 21, 14, 21, 35, 15, 18,  1, 19,\n",
      "        19, 32, 22, 34,  1, 19, 36, 15, 22,  1, 23,  6, 18,  5, 37, 15, 26, 20,\n",
      "         7, 32, 35, 29, 28, 29, 22,  1, 19, 22, 33,  1, 19, 16,  1,  8, 27, 23,\n",
      "        22,  1, 28, 27, 15, 18,  7, 13,  0,  1, 17, 26, 23, 20, 20, 29, 32, 18,\n",
      "        11,  1, 15, 28, 18,  1, 34, 22, 15, 34,  5, 33,  1, 32, 23, 17, 22, 15,\n",
      "        32, 18,  1, 18, 35, 25, 19,  1, 29, 20,  1, 39, 29, 32, 25,  8, 25, 23,\n",
      "        28, 21,  1, 14,  1, 21, 28, 23, 25,  8, 25, 32, 29, 39,  1, 20, 29,  1,\n",
      "        19, 25, 35, 18,  1, 18, 32, 15, 22, 17, 23, 32,  1, 33,  5, 34, 15, 22,\n",
      "        34,  1, 18, 28, 15,  1, 11, 18, 32, 29, 20, 20, 23, 26, 17,  1, 13,  0,\n",
      "        15, 28, 18,  1, 37, 23, 34, 22,  1, 39, 29, 35, 32,  1, 31, 35, 19, 19,\n",
      "        28,  8,  1, 23,  1, 15, 27,  1, 22, 23, 33,  1, 17, 35, 30, 16, 19, 15,\n",
      "        32, 19, 32, 10, 23, 20,  1, 20, 32, 29, 27,  1, 14,  1, 27, 29, 32, 20,\n",
      "         1, 20, 23, 10, 32, 19, 32, 15, 19, 16, 30, 35, 17,  1, 33, 23, 22,  1,\n",
      "        27, 15,  1, 23,  1,  8, 28, 19, 19, 35, 31,  1, 32, 35, 29, 39,  1, 22,\n",
      "        34, 23, 37,  1, 18, 28, 15, 13,  0, 26, 19, 10, 28, 29, 32, 34, 22, 35,\n",
      "        27, 16, 19, 32, 26, 15, 28, 18,  1, 17, 29, 27, 19, 33,  1, 16, 15, 17,\n",
      "        25,  1, 20, 32, 29, 27,  1, 16, 29, 26, 23, 28, 21, 16, 32, 29, 25, 19,\n",
      "         8, 25, 14, 25,  8, 19, 25, 29, 32, 16, 21, 28, 23, 26, 29, 16,  1, 27,\n",
      "        29, 32, 20,  1, 25, 17, 15, 16,  1, 33, 19, 27, 29, 17,  1, 18, 28, 15,\n",
      "        26, 32, 19, 16, 27, 35, 22, 34, 32, 29, 28, 10, 19, 26, 13,  0,  1, 33,\n",
      "        29,  1, 35, 28, 26, 23, 25, 19,  1, 39, 29, 35, 32, 33, 19, 26, 20, 12,\n",
      "        30, 19, 34, 32, 35, 17, 22, 23, 29, 10, 34, 19, 18, 23, 29, 35, 33,  1,\n",
      "        23, 34,  1, 37, 19, 32, 19,  1, 34, 14, 34,  1, 19, 32, 19, 37,  1, 34,\n",
      "        23,  1, 33, 35, 29, 23, 18, 19, 34, 10, 29, 23, 22, 17, 35, 32, 34, 19,\n",
      "        30, 12, 20, 26, 19, 33, 32, 35, 29, 39,  1, 19, 25, 23, 26, 28, 35,  1,\n",
      "        29, 33,  1, 13,  0, 39,  6,  1, 30, 32, 29, 35, 18,  1, 31, 35, 19, 19,\n",
      "        28,  6,  1, 34, 29,  1, 27, 15, 25, 19,  1, 34, 22, 19, 19,  1, 16, 26,\n",
      "        35, 33, 22,  8, 34, 29,  1, 34, 19, 26, 26,  1, 34, 22, 19, 19,  1, 37,\n",
      "        14, 37,  1, 19, 19, 22, 34,  1, 26, 26, 19, 34,  1, 29, 34,  8, 22, 33,\n",
      "        35, 26, 16,  1, 19, 19, 22, 34,  1, 19, 25, 15, 27,  1, 29, 34,  1,  6,\n",
      "        28, 19, 19, 35, 31,  1, 18, 35, 29, 32, 30,  1,  6, 39, 13,  0, 29, 32,\n",
      "        21, 19, 10, 37, 22, 19, 32, 19,  5, 33])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "f_WIXqxz0lU5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TD5Bj8Y6IAD4",
    "outputId": "bf23c586-1d33-4af1-b63d-ce6f90b0a528",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 15, 35, 26, 23, 28, 15, 10, 34])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HXDe8vGJCEn",
    "outputId": "588663aa-1de5-4ef7-aba0-4a96fe828353",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([30]) the target: 15\n",
      "when input is tensor([30, 15]) the target: 35\n",
      "when input is tensor([30, 15, 35]) the target: 26\n",
      "when input is tensor([30, 15, 35, 26]) the target: 23\n",
      "when input is tensor([30, 15, 35, 26, 23]) the target: 28\n",
      "when input is tensor([30, 15, 35, 26, 23, 28]) the target: 15\n",
      "when input is tensor([30, 15, 35, 26, 23, 28, 15]) the target: 10\n",
      "when input is tensor([30, 15, 35, 26, 23, 28, 15, 10]) the target: 34\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3k1Czf7LuA9",
    "outputId": "4ea8e8a0-443c-49bb-b3bf-ba36e1712999",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1,  6, 34, 33, 19, 24,  1, 18],\n",
      "        [32, 16,  1, 32, 23, 19, 22, 34],\n",
      "        [23, 29, 21,  1, 27, 15,  1, 23],\n",
      "        [39,  1, 18, 19, 32, 18, 28, 35]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 6, 34, 33, 19, 24,  1, 18, 19],\n",
      "        [16,  1, 32, 23, 19, 22, 34,  1],\n",
      "        [29, 21,  1, 27, 15,  1, 23,  1],\n",
      "        [ 1, 18, 19, 32, 18, 28, 35, 22]])\n",
      "----\n",
      "when input is [1] the target: 6\n",
      "when input is [1, 6] the target: 34\n",
      "when input is [1, 6, 34] the target: 33\n",
      "when input is [1, 6, 34, 33] the target: 19\n",
      "when input is [1, 6, 34, 33, 19] the target: 24\n",
      "when input is [1, 6, 34, 33, 19, 24] the target: 1\n",
      "when input is [1, 6, 34, 33, 19, 24, 1] the target: 18\n",
      "when input is [1, 6, 34, 33, 19, 24, 1, 18] the target: 19\n",
      "when input is [32] the target: 16\n",
      "when input is [32, 16] the target: 1\n",
      "when input is [32, 16, 1] the target: 32\n",
      "when input is [32, 16, 1, 32] the target: 23\n",
      "when input is [32, 16, 1, 32, 23] the target: 19\n",
      "when input is [32, 16, 1, 32, 23, 19] the target: 22\n",
      "when input is [32, 16, 1, 32, 23, 19, 22] the target: 34\n",
      "when input is [32, 16, 1, 32, 23, 19, 22, 34] the target: 1\n",
      "when input is [23] the target: 29\n",
      "when input is [23, 29] the target: 21\n",
      "when input is [23, 29, 21] the target: 1\n",
      "when input is [23, 29, 21, 1] the target: 27\n",
      "when input is [23, 29, 21, 1, 27] the target: 15\n",
      "when input is [23, 29, 21, 1, 27, 15] the target: 1\n",
      "when input is [23, 29, 21, 1, 27, 15, 1] the target: 23\n",
      "when input is [23, 29, 21, 1, 27, 15, 1, 23] the target: 1\n",
      "when input is [39] the target: 1\n",
      "when input is [39, 1] the target: 18\n",
      "when input is [39, 1, 18] the target: 19\n",
      "when input is [39, 1, 18, 19] the target: 32\n",
      "when input is [39, 1, 18, 19, 32] the target: 18\n",
      "when input is [39, 1, 18, 19, 32, 18] the target: 28\n",
      "when input is [39, 1, 18, 19, 32, 18, 28] the target: 35\n",
      "when input is [39, 1, 18, 19, 32, 18, 28, 35] the target: 22\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpyyAeIzQjlO",
    "outputId": "a650f8dc-da81-400b-bc59-0a595487fdb9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  6, 34, 33, 19, 24,  1, 18],\n",
      "        [32, 16,  1, 32, 23, 19, 22, 34],\n",
      "        [23, 29, 21,  1, 27, 15,  1, 23],\n",
      "        [39,  1, 18, 19, 32, 18, 28, 35]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # our input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Num7sX9CKOH",
    "outputId": "929ceb78-a639-41d6-aac7-12997b5c93f0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        xmean = x.mean(1, keepdim=True) # batch mean\n",
    "        xvar = x.var(1, keepdim=True) # batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "633T2cmnW1uk",
    "outputId": "7720fa58-0478-4e8a-86a7-502d4cce9443",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN9cK9BoXCYb",
    "outputId": "6368ece0-600e-417d-8a91-7c1e5d750ba8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcvKeBXoZFOY"
   },
   "source": [
    "### Full finished code, for reference\n",
    "Based on Karpathy's code just adapted for the string reversa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoelkOrFY8bN",
    "outputId": "961304cd-e379-40d4-dd56-8de0b91d2861",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810537 M parameters\n",
      "step 0: train loss 3.8741, val loss 3.8729\n",
      "step 500: train loss 2.3790, val loss 2.3867\n",
      "step 1000: train loss 2.0862, val loss 2.0856\n",
      "step 1500: train loss 1.8360, val loss 1.8394\n",
      "step 2000: train loss 1.7242, val loss 1.7379\n",
      "step 2500: train loss 1.6638, val loss 1.6826\n",
      "step 3000: train loss 1.6149, val loss 1.6261\n",
      "step 3500: train loss 1.5967, val loss 1.6194\n",
      "step 4000: train loss 1.5558, val loss 1.5727\n",
      "step 4500: train loss 1.5413, val loss 1.5584\n",
      "step 5000: train loss 1.5160, val loss 1.5304\n",
      "step 5500: train loss 1.5074, val loss 1.5272\n",
      "step 6000: train loss 1.4936, val loss 1.5087\n",
      "step 6500: train loss 1.4913, val loss 1.4957\n",
      "step 7000: train loss 1.4708, val loss 1.4808\n",
      "step 7500: train loss 1.4649, val loss 1.4694\n",
      "step 8000: train loss 1.4456, val loss 1.4662\n",
      "step 8500: train loss 1.4575, val loss 1.4556\n",
      "step 9000: train loss 1.4283, val loss 1.4439\n",
      "step 9500: train loss 1.4094, val loss 1.4311\n",
      "step 10000: train loss 1.4192, val loss 1.4341\n",
      "step 10500: train loss 1.3956, val loss 1.4295\n",
      "step 11000: train loss 1.4038, val loss 1.4175\n",
      "step 11500: train loss 1.3995, val loss 1.4147\n",
      "step 12000: train loss 1.4015, val loss 1.4156\n",
      "step 12500: train loss 1.3941, val loss 1.4064\n",
      "step 13000: train loss 1.3848, val loss 1.3987\n",
      "step 13500: train loss 1.3830, val loss 1.4022\n",
      "step 14000: train loss 1.3886, val loss 1.4155\n",
      "step 14500: train loss 1.3772, val loss 1.3959\n",
      "step 15000: train loss 1.3751, val loss 1.3903\n",
      "step 15500: train loss 1.3754, val loss 1.3750\n",
      "step 16000: train loss 1.3623, val loss 1.3847\n",
      "step 16500: train loss 1.3697, val loss 1.3929\n",
      "step 17000: train loss 1.3446, val loss 1.3740\n",
      "step 17500: train loss 1.3537, val loss 1.3723\n",
      "step 18000: train loss 1.3529, val loss 1.3738\n",
      "step 18500: train loss 1.3517, val loss 1.3803\n",
      "step 19000: train loss 1.3466, val loss 1.3664\n",
      "step 19500: train loss 1.3531, val loss 1.3730\n",
      "step 20000: train loss 1.3363, val loss 1.3616\n",
      "step 20500: train loss 1.3281, val loss 1.3568\n",
      "step 21000: train loss 1.3413, val loss 1.3555\n",
      "step 21500: train loss 1.3418, val loss 1.3518\n",
      "step 22000: train loss 1.3276, val loss 1.3342\n",
      "step 22500: train loss 1.3308, val loss 1.3599\n",
      "step 23000: train loss 1.3235, val loss 1.3606\n",
      "step 23500: train loss 1.3309, val loss 1.3592\n",
      "step 24000: train loss 1.3146, val loss 1.3419\n",
      "step 24500: train loss 1.3148, val loss 1.3475\n",
      "step 25000: train loss 1.3236, val loss 1.3439\n",
      "step 25500: train loss 1.3240, val loss 1.3399\n",
      "step 26000: train loss 1.3141, val loss 1.3332\n",
      "step 26500: train loss 1.3119, val loss 1.3338\n",
      "step 27000: train loss 1.3093, val loss 1.3375\n",
      "step 27500: train loss 1.3074, val loss 1.3449\n",
      "step 28000: train loss 1.3077, val loss 1.3296\n",
      "step 28500: train loss 1.3036, val loss 1.3238\n",
      "step 29000: train loss 1.2984, val loss 1.3168\n",
      "step 29500: train loss 1.3002, val loss 1.3315\n",
      "step 29999: train loss 1.2944, val loss 1.3239\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 64 # what is the maximum context length for predictions?\n",
    "max_iters = 30000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "sentences = [] \n",
    "with open(\"output_data_50.txt\",\"r\") as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "text = \"\".join(sentences[:50000])\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 22, 23, 33, 1, 23, 33, 1, 15, 1, 34, 19, 33, 34, 14]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"this is a test_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "fjjvMifYZf7x",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34, 22, 23, 33,  1, 23, 33,  1, 15,  1, 34, 19, 33, 34, 14]],\n",
      "       device='cuda:0')\n",
      "this is a test_tset a si siht \n"
     ]
    }
   ],
   "source": [
    "# generate from the model\n",
    "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "context = torch.tensor(encode(\"this is a test_\"), dtype = torch.long , device = device).view(1,-1)\n",
    "print(context)\n",
    "print(decode(m.generate(context, max_new_tokens=15)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving checkpoint to ./checkpoints/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "out_dir = \"./checkpoints/\"\n",
    "checkpoint = {\n",
    "                    'model': m.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict()\n",
    "                }\n",
    "print(f\"saving checkpoint to {out_dir}\")\n",
    "torch.save(checkpoint, os.path.join(out_dir, 'string_reverse_v1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(m , os.path.join(out_dir, 'string_reverse_v1_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>string</th>\n",
       "      <th>context</th>\n",
       "      <th>expected</th>\n",
       "      <th>generations</th>\n",
       "      <th>Rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>go?ratcl_lctar?og^\\n</td>\n",
       "      <td>go?ratcl_</td>\n",
       "      <td>lctar?og^</td>\n",
       "      <td>lctarbgni</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>pedient du_ud tneidep^\\n</td>\n",
       "      <td>pedient du_</td>\n",
       "      <td>ud tneidep^</td>\n",
       "      <td>ud tneidebi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>haste, an_na ,etsah ^\\n</td>\n",
       "      <td>haste, an_</td>\n",
       "      <td>na ,etsah ^</td>\n",
       "      <td>na ,etsah h</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>y's answer_rewsna s'y^\\n</td>\n",
       "      <td>y's answer_</td>\n",
       "      <td>rewsna s'y^</td>\n",
       "      <td>rewsna s'ye</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>es beheld!_!dleheb se^\\n</td>\n",
       "      <td>es beheld!_</td>\n",
       "      <td>!dleheb se^</td>\n",
       "      <td>!dleb sevav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size                    string      context     expected  generations  \\\n",
       "0    10      go?ratcl_lctar?og^\\n    go?ratcl_    lctar?og^    lctarbgni   \n",
       "1    10  pedient du_ud tneidep^\\n  pedient du_  ud tneidep^  ud tneidebi   \n",
       "2    10   haste, an_na ,etsah ^\\n   haste, an_  na ,etsah ^  na ,etsah h   \n",
       "3    10  y's answer_rewsna s'y^\\n  y's answer_  rewsna s'y^  rewsna s'ye   \n",
       "4    10  es beheld!_!dleheb se^\\n  es beheld!_  !dleheb se^  !dleb sevav   \n",
       "\n",
       "   Rouge_scores  \n",
       "0             4  \n",
       "1             2  \n",
       "2             1  \n",
       "3             1  \n",
       "4             5  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "    context = torch.tensor(encode(text), dtype = torch.long , device = device).view(1,-1)\n",
    "    generations =  decode(m.generate(context, max_new_tokens=len(text) + 10)[0].tolist()).split(\"_\")[1]\n",
    "    index = generations.find('^')\n",
    "    if index == -1:\n",
    "        print(\"EOS did not happen\")\n",
    "    index = len(text)\n",
    "    return generations[:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:05, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:10,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:00<00:11,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:01<00:11,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:01<00:11,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:01<00:14,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:01<00:15,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:02<00:15,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:02<00:15,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:02<00:15,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:03<00:15,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n",
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:03<00:16,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:03<00:17,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:04<00:18,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:04<00:18,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:04<00:18,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:04<00:18,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:05<00:18,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:05<00:18,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:05<00:18,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:05<00:17,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:06<00:19,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:06<00:19,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:18<00:17,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS did not happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "data_df[\"generations\"] = data_df[\"context\"].progress_apply(lambda x : generate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>string</th>\n",
       "      <th>context</th>\n",
       "      <th>expected</th>\n",
       "      <th>generations</th>\n",
       "      <th>Rouge_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>go?ratcl_lctar?og^\\n</td>\n",
       "      <td>go?ratcl_</td>\n",
       "      <td>lctar?og^</td>\n",
       "      <td>lctar,og</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>pedient du_ud tneidep^\\n</td>\n",
       "      <td>pedient du_</td>\n",
       "      <td>ud tneidep^</td>\n",
       "      <td>ud tneidepe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>haste, an_na ,etsah ^\\n</td>\n",
       "      <td>haste, an_</td>\n",
       "      <td>na ,etsah ^</td>\n",
       "      <td>na ,etsah t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>y's answer_rewsna s'y^\\n</td>\n",
       "      <td>y's answer_</td>\n",
       "      <td>rewsna s'y^</td>\n",
       "      <td>rewsna s'yo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>es beheld!_!dleheb se^\\n</td>\n",
       "      <td>es beheld!_</td>\n",
       "      <td>!dleheb se^</td>\n",
       "      <td>!dleheb sem</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size                    string      context     expected  generations  \\\n",
       "0    10      go?ratcl_lctar?og^\\n    go?ratcl_    lctar?og^    lctar,og    \n",
       "1    10  pedient du_ud tneidep^\\n  pedient du_  ud tneidep^  ud tneidepe   \n",
       "2    10   haste, an_na ,etsah ^\\n   haste, an_  na ,etsah ^  na ,etsah t   \n",
       "3    10  y's answer_rewsna s'y^\\n  y's answer_  rewsna s'y^  rewsna s'yo   \n",
       "4    10  es beheld!_!dleheb se^\\n  es beheld!_  !dleheb se^  !dleheb sem   \n",
       "\n",
       "   Rouge_scores  \n",
       "0             4  \n",
       "1             2  \n",
       "2             1  \n",
       "3             1  \n",
       "4             5  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein_distance(\"this is an amazing sentence\" , \"this is a okay sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score(str1, str2): \n",
    "    scoring = Rouge()\n",
    "    if len(str1) == 0 or len(str2) == 0:\n",
    "        return max(len(str1),len(str2))\n",
    "    scores= levenshtein_distance(str1, str2)\n",
    "    return scores\n",
    "data_df['Rouge_scores'] = data_df.apply(lambda x : score(x['generations'],x['expected']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "char_length = []\n",
    "distance=[] \n",
    "error = []\n",
    "for name , group in data_df.groupby(\"size\"): \n",
    "    char_length.append(name)\n",
    "    distance.append(np.mean(group['Rouge_scores']))\n",
    "    error.append(np.std(group['Rouge_scores'])/np.sqrt(len(group)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your lists look something like this:\n",
    "# char_length = [list of character lengths]\n",
    "# distance = [list of distances]\n",
    "# error = [list of errors]\n",
    "\n",
    "plt.errorbar(char_length, distance, yerr=error, fmt='o', ecolor='red', capsize=5)\n",
    "plt.xlabel('String to reverse Length')\n",
    "plt.ylabel('Levenshtein Distance')\n",
    "plt.title('Levenshtein Distance vs Character Length with Error Bars Block size 50')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_answerbot",
   "language": "python",
   "name": "conda_answerbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
